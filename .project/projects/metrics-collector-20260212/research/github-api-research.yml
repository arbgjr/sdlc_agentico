---
# Research Brief - GitHub APIs for Metrics Collection
# Generated by: domain-researcher
# Phase: 1 (Discovery)
# Date: 2026-02-12T20:22:24Z

research_brief:
  topic: "GitHub APIs for Metrics Collection (Copilot, DORA, Velocity)"
  date: "2026-02-12"
  researcher: "domain-researcher"

  executive_summary: |
    GitHub provides comprehensive APIs for collecting the required metrics:
    1. Copilot Metrics API (Enterprise Cloud) - dedicated endpoints for usage stats
    2. REST API - commits, PRs, releases, workflows for DORA/Velocity
    3. GraphQL API - bulk queries with better performance for large datasets

    Key finding: Copilot Metrics API endpoints will be deprecated on April 2, 2026.
    Migration to newer "Copilot usage metrics" endpoints is recommended.
    Rate limits are manageable (5000 req/hour authenticated).

  key_findings:
    # Copilot API Findings
    - finding: "Copilot Metrics API provides enterprise, org, and team-level data"
      confidence: high
      details: |
        Four main endpoints available:
        - GET /enterprises/{enterprise}/copilot/metrics
        - GET /enterprises/{enterprise}/team/{team_slug}/copilot/metrics
        - GET /orgs/{org}/copilot/metrics
        - GET /orgs/{org}/team/{team_slug}/copilot/metrics
      sources:
        - title: "REST API endpoints for Copilot metrics - GitHub Enterprise Cloud Docs"
          url: "https://docs.github.com/en/enterprise-cloud@latest/rest/copilot/copilot-metrics"
          type: "official"

    - finding: "Copilot metrics require minimum 5 licensed users to return data"
      confidence: high
      details: "Privacy threshold to prevent individual identification"
      sources:
        - title: "GitHub Copilot usage metrics"
          url: "https://docs.github.com/en/enterprise-cloud@latest/copilot/concepts/copilot-metrics"
          type: "official"

    - finding: "DEPRECATION: Current Copilot metrics endpoints cease operation April 2, 2026"
      confidence: high
      details: "Must migrate to newer Copilot usage metrics endpoints"
      impact: "CRITICAL - project must use new API from start"
      sources:
        - title: "REST API endpoints for Copilot metrics"
          url: "https://docs.github.com/en/enterprise-cloud@latest/rest/copilot/copilot-metrics"
          type: "official"

    - finding: "Historical Copilot data available for up to 100 days"
      confidence: high
      details: "Metrics calculated daily for previous day"
      sources:
        - title: "GitHub Copilot usage metrics"
          url: "https://docs.github.com/en/enterprise-cloud@latest/copilot/concepts/copilot-metrics"
          type: "official"

    # DORA Metrics Findings
    - finding: "DORA metrics can be calculated from GitHub Actions workflow runs"
      confidence: high
      details: |
        - Deployment Frequency: Count successful workflow runs on main branch
        - Lead Time: PR open time + deployment time
        - MTTR: Requires external alerting integration
        - Change Failure Rate: Requires manual classification or rollback detection
      sources:
        - title: "DeveloperMetrics/DevOpsMetrics"
          url: "https://github.com/DeveloperMetrics/DevOpsMetrics"
          type: "community"
        - title: "How to Calculate DORA Metrics"
          url: "https://www.aviator.co/blog/how-to-calculate-dora-metrics/"
          type: "blog"

    - finding: "GitHub Actions DORA tools available in Marketplace"
      confidence: high
      details: |
        - dora-deployment-frequency action
        - dora-lead-time-for-changes action
        Provide good starting point for calculations
      sources:
        - title: "DORA deployment frequency - GitHub Marketplace"
          url: "https://github.com/marketplace/actions/dora-deployment-frequency"
          type: "tool"

    # Velocity Metrics Findings
    - finding: "PR review time requires combining multiple API calls"
      confidence: high
      details: |
        Key timestamps from PR API:
        - created_at: PR creation time
        - first_review_at: First review timestamp (from reviews endpoint)
        - merged_at: PR merge time
        Calculate: Time to first review, Total review time
      sources:
        - title: "How to track code review metrics in GitHub"
          url: "https://graphite.com/guides/track-code-review-metrics-github"
          type: "blog"

    - finding: "GraphQL API more efficient for bulk PR/commit queries"
      confidence: high
      details: |
        - Single query can fetch related data (PR + reviews + commits)
        - Max 1000 results per search query
        - Rate limit: separate from REST (point-based system)
      sources:
        - title: "Queries - GitHub Docs"
          url: "https://docs.github.com/en/graphql/reference/queries"
          type: "official"

  api_specifications:
    copilot_api:
      base_url: "https://api.github.com"
      endpoints:
        enterprise_metrics:
          path: "/enterprises/{enterprise}/copilot/metrics"
          method: "GET"
          auth: "manage_billing:copilot OR read:enterprise"
          note: "Does NOT support fine-grained PATs"
        org_metrics:
          path: "/orgs/{org}/copilot/metrics"
          method: "GET"
          auth: "manage_billing:copilot OR read:org"
          note: "Supports GitHub App tokens and fine-grained PATs"
        usage_reports:
          path: "/enterprises/{enterprise}/copilot/usage"
          method: "GET"
          response: "NDJSON format with daily records"
          auth: "View Enterprise Copilot Metrics permission"

      available_metrics:
        adoption:
          - metric: "daily_active_users"
            description: "Unique users engaging with Copilot per day"
          - metric: "weekly_active_users"
            description: "Unique users engaging with Copilot per week"
          - metric: "total_active_users"
            description: "Licensed personnel active during current month"
          - metric: "agent_adoption"
            description: "Percentage using Copilot agents"

        code_completion:
          - metric: "acceptance_rate"
            description: "Percentage of suggestions accepted by users"
            formula: "suggestions_accepted / suggestions_shown"
          - metric: "suggestions_shown"
            description: "Total code suggestions displayed"
          - metric: "suggestions_accepted"
            description: "Total code suggestions accepted"

        usage_breakdown:
          - metric: "by_language"
            description: "Usage distribution by programming language"
          - metric: "by_editor"
            description: "Usage distribution by IDE"
          - metric: "by_model"
            description: "AI model used for completions/chat"

        code_generation:
          - metric: "loc_suggested_to_add_sum"
            description: "Lines of code suggested to add"
          - metric: "loc_added_sum"
            description: "Lines of code actually added"
          - metric: "user_initiated_interaction_count"
            description: "Number of explicit prompts sent"

    rest_api:
      base_url: "https://api.github.com"
      rate_limit: "5000 requests/hour (authenticated)"
      endpoints:
        commits:
          path: "/repos/{owner}/{repo}/commits"
          use_case: "Commit frequency, code churn"
        pulls:
          path: "/repos/{owner}/{repo}/pulls"
          use_case: "PR throughput, review time"
        pull_reviews:
          path: "/repos/{owner}/{repo}/pulls/{pull_number}/reviews"
          use_case: "Time to first review"
        workflow_runs:
          path: "/repos/{owner}/{repo}/actions/runs"
          use_case: "Deployment frequency, lead time"
        releases:
          path: "/repos/{owner}/{repo}/releases"
          use_case: "Release frequency"

    graphql_api:
      endpoint: "https://api.github.com/graphql"
      rate_limit: "5000 points/hour"
      advantages:
        - "Single query for related data"
        - "Reduce number of API calls"
        - "More efficient for bulk operations"
      limitations:
        - "Max 1000 results per search"
        - "Complex query syntax"
        - "Point-based rate limiting"

  metrics_calculation:
    dora:
      deployment_frequency:
        definition: "How often code is deployed to production"
        calculation: "Count of successful workflow runs on main branch / time period"
        data_sources:
          - "GET /repos/{owner}/{repo}/actions/runs?branch=main&status=success"
        elite_threshold: "Multiple deploys per day"
        low_threshold: "Less than once per month"

      lead_time_for_changes:
        definition: "Time from commit to production"
        calculation: "Average(merge_time - first_commit_time) + Average(deploy_time - merge_time)"
        data_sources:
          - "GET /repos/{owner}/{repo}/pulls?state=closed"
          - "GET /repos/{owner}/{repo}/pulls/{n}/commits"
          - "GET /repos/{owner}/{repo}/actions/runs"
        elite_threshold: "Less than 1 hour"
        low_threshold: "More than 6 months"

      mean_time_to_recovery:
        definition: "Time to recover from production failure"
        calculation: "Average(incident_resolved_time - incident_detected_time)"
        data_sources:
          - "Requires external alerting system"
          - "Or: GitHub Issues labeled 'incident' with opened/closed times"
        elite_threshold: "Less than 1 hour"
        low_threshold: "More than 1 week"
        note: "Most complex to calculate from GitHub alone"

      change_failure_rate:
        definition: "Percentage of deployments causing failures"
        calculation: "Failed deployments / Total deployments"
        data_sources:
          - "Manual classification required"
          - "Or: Detect rollback commits/workflows"
          - "Or: Track issues linked to releases"
        elite_threshold: "0-15%"
        low_threshold: "46-60%"

    velocity:
      commit_frequency:
        definition: "How often developers commit code"
        calculation: "Count of commits / time period / number of developers"
        data_sources:
          - "GET /repos/{owner}/{repo}/commits"
          - "GET /repos/{owner}/{repo}/stats/contributors"

      pr_throughput:
        definition: "Number of PRs merged per time period"
        calculation: "Count of merged PRs / time period"
        data_sources:
          - "GET /repos/{owner}/{repo}/pulls?state=closed"
          - "Filter: merged_at IS NOT NULL"

      review_time:
        definition: "Time from PR creation to first review"
        calculation: "Average(first_review_time - pr_created_time)"
        data_sources:
          - "GET /repos/{owner}/{repo}/pulls"
          - "GET /repos/{owner}/{repo}/pulls/{n}/reviews"

      code_churn:
        definition: "Lines added vs deleted over time"
        calculation: "Additions - Deletions over rolling window"
        data_sources:
          - "GET /repos/{owner}/{repo}/stats/code_frequency"
          - "Or: Sum from individual commits"

  best_practices:
    - practice: "Use GraphQL for bulk data retrieval"
      rationale: "Reduces API calls, stays within rate limits"
      source: "GitHub GraphQL documentation"

    - practice: "Implement exponential backoff for rate limits"
      rationale: "GitHub returns 403 with retry-after header when rate limited"
      source: "GitHub API best practices"

    - practice: "Cache API responses locally"
      rationale: "Historical data doesn't change, avoid repeated calls"
      source: "Common practice"

    - practice: "Use GitHub App authentication over PATs"
      rationale: "Higher rate limits (15000 vs 5000), better security"
      source: "GitHub documentation"

    - practice: "Process data incrementally"
      rationale: "Only fetch new data since last run"
      source: "Performance optimization"

    - practice: "Use conditional requests (If-None-Match)"
      rationale: "Reduce bandwidth, get 304 for unchanged data"
      source: "GitHub API documentation"

  anti_patterns:
    - pattern: "Fetching all commits without pagination"
      reason: "API returns max 100 per page, will miss data"
      alternative: "Always implement pagination with Link header"

    - pattern: "Making synchronous API calls"
      reason: "Slow and hits rate limits quickly"
      alternative: "Use async/await with rate limit awareness"

    - pattern: "Storing raw API responses"
      reason: "Wastes storage, contains unnecessary data"
      alternative: "Extract and store only needed metrics"

    - pattern: "Calculating MTTR from GitHub alone"
      reason: "GitHub doesn't track production incidents natively"
      alternative: "Integrate with incident management (PagerDuty, etc)"

  knowledge_gaps:
    - "Exact API endpoints for newer Copilot usage metrics (post-deprecation)"
    - "How to handle multi-organization aggregation with separate tokens"
    - "Best practice for MTTR calculation without incident management system"
    - "Optimal polling interval vs API rate limits"

  recommendations:
    - "Use the newer Copilot usage metrics API from the start (not deprecated endpoints)"
    - "Implement GitHub App for authentication (higher rate limits)"
    - "Use GraphQL for PR/commit data, REST for Copilot and workflows"
    - "Design for incremental data collection (since last run)"
    - "Plan for MTTR approximation using GitHub Issues with 'incident' label"
    - "Build data model to support multiple organizations from day one"

  architecture_considerations:
    authentication:
      options:
        - name: "GitHub App"
          pros: ["Higher rate limits", "Per-repo installation", "Better security"]
          cons: ["More complex setup", "Need separate app per org"]
        - name: "Personal Access Token (classic)"
          pros: ["Simple setup", "Works for enterprise endpoints"]
          cons: ["Lower rate limits", "Tied to user account"]
        - name: "Fine-grained PAT"
          pros: ["Scoped permissions", "Better security than classic"]
          cons: ["Does not work with enterprise Copilot endpoints"]
      recommendation: "GitHub App for repo data, classic PAT for enterprise Copilot"

    data_storage:
      requirements:
        - "Time-series data for trending"
        - "Aggregation support (daily, weekly, monthly)"
        - "Multi-organization isolation"
        - "PowerBI compatibility"
      options:
        - name: "PostgreSQL with TimescaleDB"
          fit: "Excellent for time-series, good PowerBI support"
        - name: "Azure SQL Database"
          fit: "Native PowerBI integration, familiar SQL"
        - name: "Parquet files on blob storage"
          fit: "Simple, cheap, PowerBI DirectQuery support"

    scheduling:
      frequency: "Daily collection recommended"
      timing: "After GitHub's daily metric calculation (midnight UTC + 3 days)"
      options:
        - "Azure Functions with Timer Trigger"
        - "GitHub Actions scheduled workflow"
        - "Kubernetes CronJob"

  corpus_additions:
    - type: "concept"
      title: "DORA Metrics"
      content: |
        DevOps Research and Assessment metrics:
        1. Deployment Frequency - How often deploys to production
        2. Lead Time for Changes - Commit to production time
        3. MTTR - Time to recover from failure
        4. Change Failure Rate - Percentage of failed deploys

    - type: "concept"
      title: "GitHub Copilot Metrics"
      content: |
        Key metrics for Copilot adoption:
        - Acceptance Rate: suggestions accepted / suggestions shown
        - Active Users: DAU, WAU, MAU
        - Usage by Language: distribution across programming languages
        - Usage by Editor: distribution across IDEs (VS Code, JetBrains, etc)
